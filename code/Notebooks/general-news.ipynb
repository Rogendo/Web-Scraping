{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to news_articles.csv\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urljoin  \n",
    "from selenium import webdriver  \n",
    "from selenium.webdriver.chrome.service import Service  \n",
    "from selenium.webdriver.common.by import By  \n",
    "from selenium.webdriver.support.ui import WebDriverWait  \n",
    "from selenium.webdriver.support import expected_conditions as EC  \n",
    "from bs4 import BeautifulSoup  \n",
    "import pandas as pd  \n",
    "import time  \n",
    "\n",
    "topics = ['breaking-news', 'trending','business','entertainment','politics','health', 'celebrities', 'economy','sports']  \n",
    "\n",
    "def setup_driver():  \n",
    "    \"\"\"Configure and return a headless Chrome driver\"\"\"  \n",
    "    options = webdriver.ChromeOptions()  \n",
    "    options.add_argument(\"--headless\")  \n",
    "    options.add_argument(\"--disable-gpu\")  \n",
    "    options.add_argument(\"--no-sandbox\")  \n",
    "    options.add_argument(\"--disable-dev-shm-usage\")  \n",
    "    options.add_argument(\"--window-size=1920x1080\")  \n",
    "    \n",
    "    return webdriver.Chrome(options=options)  \n",
    "\n",
    "def get_titles_links(driver, url):  \n",
    "    \"\"\"Return the page source of the given URL\"\"\"  \n",
    "    try:  \n",
    "        driver.get(url)  \n",
    "        html = driver.page_source  \n",
    "        soup = BeautifulSoup(html, \"html.parser\")  \n",
    "        articles = soup.find_all(\"article\", class_='l-post grid-post grid-base-post')  \n",
    "        \n",
    "        data = []  \n",
    "        for post in articles:  \n",
    "            title = post.find(\"h2\", class_=\"is-title post-title\").text  \n",
    "            link = post.find(\"h2\").find(\"a\")[\"href\"]  \n",
    "            data.append({\"title\": title, \"link\": link})  \n",
    "        \n",
    "        # Check if there's a next page  \n",
    "        next_page = soup.find(\"a\", class_=\"next page-numbers\")  \n",
    "        return data, next_page is not None  \n",
    "    \n",
    "    except Exception as e:  \n",
    "        print(f\"Error fetching page: {e}\")  \n",
    "        return [], False  \n",
    "\n",
    "def get_page(driver, url):  \n",
    "    \"\"\"Return the page source of the given URL\"\"\"  \n",
    "    try:  \n",
    "        driver.get(url)  \n",
    "        html = driver.page_source  \n",
    "        soup = BeautifulSoup(html, \"html.parser\")  \n",
    "        content = soup.find('div', class_='post-content cf entry-content content-spacious')  \n",
    "        if content:  \n",
    "            paragraphs = content.find_all('p')  \n",
    "            return ' '.join([p.text for p in paragraphs])  \n",
    "        return \"\"  \n",
    "    except Exception as e:  \n",
    "        print(f\"Error fetching content: {e}\")  \n",
    "        return \"\"  \n",
    "\n",
    "def main():  \n",
    "    driver = setup_driver()  \n",
    "    all_data = []  \n",
    "    \n",
    "    for topic in topics:  \n",
    "        page = 1  \n",
    "        has_next_page = True  \n",
    "        \n",
    "        while has_next_page:  \n",
    "            url = f'https://newshub.co.ke/category/{topic}/page/{page}/'  \n",
    "            articles, has_next_page = get_titles_links(driver, url)  \n",
    "            \n",
    "            for article in articles:  \n",
    "                content = get_page(driver, article['link'])  \n",
    "                all_data.append({  \n",
    "                    \"title\": article['title'],  \n",
    "                    \"link\": article['link'],  \n",
    "                    \"content\": content  \n",
    "                })  \n",
    "            \n",
    "            page += 1  \n",
    "            time.sleep(1)  \n",
    "    \n",
    "    driver.quit()  \n",
    "    \n",
    "    # Convert data to DataFrame and save to CSV  \n",
    "    df = pd.DataFrame(all_data)  \n",
    "    df.to_csv('news_articles_v2.csv', index=False)  \n",
    "    print(\"Data has been saved to news_articles.csv\")  \n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    main()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
